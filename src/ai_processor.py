"""
M√≥dulo de Procesamiento con IA para Labortrovilo
AI-Traktada Modulo por Labortrovilo
AI Processing Module for Labortrovilo

Senior AI Engineer Architecture
Procesa descripciones de trabajo con LLMs (OpenAI/Claude) para extraer informaci√≥n estructurada
"""
import json
import hashlib
import logging
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path

from sqlalchemy.orm import Session
from sqlalchemy import and_

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

from src.models import Job
from src.database import get_db
from config import settings

# Configurar logging / Agordi registradon / Configure logging
logger = logging.getLogger(__name__)


class AIJobProcessor:
    """
    Procesador de ofertas de trabajo con IA
    AI-bazita laboroferta traktilo
    AI-powered job offer processor
    
    Caracter√≠sticas / Trajtoj / Features:
    - Extracci√≥n estructurada con LLMs
    - Sistema de cach√© para optimizar costos
    - Soporte para OpenAI y Claude/Anthropic
    - An√°lisis de red flags
    """
    
    def __init__(
        self, 
        provider: str = "openai",
        model: str = None,
        api_key: str = None
    ):
        """
        Inicializa el procesador de IA
        Ekigas la AI-traktilon
        Initializes the AI processor
        
        Args:
            provider: "openai" o "anthropic"
            model: Modelo espec√≠fico (ej: "gpt-4", "claude-3-opus")
            api_key: API key (si no est√° en .env)
        """
        self.provider = provider.lower()
        self.api_key = api_key or self._get_api_key()
        
        # Seleccionar modelo / Elekti modelon / Select model
        if model:
            self.model = model
        elif self.provider == "openai":
            self.model = "gpt-4o-mini"  # M√°s econ√≥mico que gpt-4
        elif self.provider == "anthropic":
            self.model = "claude-3-haiku-20240307"  # M√°s econ√≥mico que opus
        else:
            raise ValueError(f"Provider no soportado: {provider}")
        
        # Inicializar cliente / Ekigi klienton / Initialize client
        self._init_client()
        
        # Sistema de cach√© / Ka≈ùmemora sistemo / Cache system
        self.cache_file = Path("cache_ai_processing.json")
        self.cache = self._load_cache()
        
        logger.info(f"ü§ñ AIJobProcessor inicializado: {self.provider} / {self.model}")
    
    def _get_api_key(self) -> str:
        """Obtiene la API key desde configuraci√≥n"""
        if self.provider == "openai":
            key = getattr(settings, 'OPENAI_API_KEY', None)
            if not key:
                raise ValueError(
                    "OPENAI_API_KEY no configurada. "
                    "Agr√©gala a tu archivo .env: OPENAI_API_KEY=sk-..."
                )
            return key
        elif self.provider == "anthropic":
            key = getattr(settings, 'ANTHROPIC_API_KEY', None)
            if not key:
                raise ValueError(
                    "ANTHROPIC_API_KEY no configurada. "
                    "Agr√©gala a tu archivo .env: ANTHROPIC_API_KEY=sk-ant-..."
                )
            return key
        else:
            raise ValueError(f"Provider desconocido: {self.provider}")
    
    def _init_client(self):
        """Inicializa el cliente de IA"""
        if self.provider == "openai":
            if not OPENAI_AVAILABLE:
                raise ImportError(
                    "OpenAI no instalado. Ejecuta: pip install openai"
                )
            self.client = OpenAI(api_key=self.api_key)
            logger.info("‚úì Cliente OpenAI inicializado")
            
        elif self.provider == "anthropic":
            if not ANTHROPIC_AVAILABLE:
                raise ImportError(
                    "Anthropic no instalado. Ejecuta: pip install anthropic"
                )
            self.client = anthropic.Anthropic(api_key=self.api_key)
            logger.info("‚úì Cliente Anthropic inicializado")
    
    def _load_cache(self) -> Dict[str, Dict]:
        """
        Carga el cach√© desde disco
        ≈úargas ka≈ùmemoron de disko
        Loads cache from disk
        """
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
                logger.info(f"‚úì Cach√© cargado: {len(cache)} entradas")
                return cache
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error cargando cach√©: {e}")
                return {}
        return {}
    
    def _save_cache(self):
        """Guarda el cach√© en disco"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, indent=2, ensure_ascii=False)
            logger.info(f"‚úì Cach√© guardado: {len(self.cache)} entradas")
        except Exception as e:
            logger.error(f"‚úó Error guardando cach√©: {e}")
    
    def _compute_hash(self, text: str) -> str:
        """
        Calcula hash SHA256 de un texto
        Kalkulas SHA256-ha≈ùon de teksto
        Computes SHA256 hash of text
        """
        return hashlib.sha256(text.encode('utf-8')).hexdigest()
    
    def _build_system_prompt(self) -> str:
        """
        Construye el prompt del sistema para la IA
        Konstruas la sisteman instigon por la AI
        Builds the system prompt for the AI
        """
        return """Eres un AI Engineer experto en an√°lisis de ofertas de trabajo tecnol√≥gicas.

Tu tarea es analizar descripciones de ofertas de empleo y extraer informaci√≥n estructurada en formato JSON.

IMPORTANTE: Tu respuesta DEBE ser √öNICAMENTE un objeto JSON v√°lido, sin texto adicional antes o despu√©s.

Estructura JSON requerida:
{
  "tech_stack": ["lista", "de", "tecnolog√≠as"],
  "seniority_level": "uno de: Intern, Junior, Mid, Senior, Lead, C-Level",
  "is_remote": true o false,
  "salary_estimate": "rango estimado si no est√° expl√≠cito, ej: '$80k-$120k USD'",
  "hiring_intent": "growth o replacement",
  "red_flags": ["lista", "de", "problemas", "potenciales"]
}

GU√çA DE EXTRACCI√ìN:

1. tech_stack: 
   - Lista limpia de lenguajes, frameworks, herramientas
   - Normaliza nombres (ej: "ReactJS" ‚Üí "React", "postgresql" ‚Üí "PostgreSQL")
   - Solo tecnolog√≠as expl√≠citamente mencionadas

2. seniority_level:
   - Intern: pr√°cticas, becario, trainee
   - Junior: 0-2 a√±os experiencia, junior
   - Mid: 2-5 a√±os, mid-level, "solid experience"
   - Senior: 5+ a√±os, senior, "extensive experience"
   - Lead: tech lead, staff engineer, principal
   - C-Level: CTO, VP Engineering, Director

3. is_remote:
   - true si menciona: remote, remoto, work from home, anywhere
   - false si especifica ubicaci√≥n f√≠sica obligatoria

4. salary_estimate:
   - Si hay rango expl√≠cito, √∫salo
   - Si no, estima bas√°ndote en:
     * Seniority level
     * Ubicaci√≥n (si se menciona)
     * Stack tecnol√≥gico (tecnolog√≠as premium pagan m√°s)
   - Formato: "$80k-$120k USD" o "‚Ç¨60k-‚Ç¨90k EUR"

5. hiring_intent:
   - "growth": expansi√≥n, scaling, new team, new project
   - "replacement": backfill, replacing, maintaining current team

6. red_flags:
   - "Demasiadas tecnolog√≠as no relacionadas" (ej: pide Java, Python, Ruby, Go)
   - "Horarios poco claros" (ej: "flexibilidad" sin detalles)
   - "Salario muy bajo para el nivel" 
   - "Requisitos irreales" (ej: 10 a√±os exp en tech de 3 a√±os)
   - "Cultura t√≥xica" (ej: "work hard, play hard", "ninjas")
   - "Descripci√≥n vaga" (muy corta o sin detalles t√©cnicos)

Responde SOLO con el objeto JSON, sin markdown, sin explicaciones."""

    def _build_user_prompt(self, job_data: Dict[str, Any]) -> str:
        """Construye el prompt del usuario con los datos del trabajo"""
        title = job_data.get('title', 'Unknown')
        company = job_data.get('company_name', 'Unknown')
        location = job_data.get('location', 'Unknown')
        description = job_data.get('description', '')
        
        # Truncar descripci√≥n si es muy larga (para ahorrar tokens)
        if len(description) > 4000:
            description = description[:4000] + "..."
        
        return f"""Analiza esta oferta de trabajo:

T√çTULO: {title}
EMPRESA: {company}
UBICACI√ìN: {location}

DESCRIPCI√ìN:
{description}

Responde √öNICAMENTE con el objeto JSON estructurado."""

    def process_description(
        self, 
        job_data: Dict[str, Any],
        use_cache: bool = True
    ) -> Optional[Dict[str, Any]]:
        """
        Procesa una descripci√≥n de trabajo con IA
        Traktas labopriskribon per AI
        Processes job description with AI
        
        Args:
            job_data: Diccionario con datos del trabajo (debe incluir 'description')
            use_cache: Si True, usa cach√© para evitar llamadas duplicadas
            
        Returns:
            Diccionario con campos procesados o None si falla
        """
        description = job_data.get('description', '')
        if not description or len(description.strip()) < 50:
            logger.warning("‚ö†Ô∏è Descripci√≥n muy corta o vac√≠a, saltando procesamiento IA")
            return None
        
        # Verificar cach√© / Kontroli ka≈ùmemoron / Check cache
        desc_hash = self._compute_hash(description)
        
        if use_cache and desc_hash in self.cache:
            logger.info(f"‚úì Datos encontrados en cach√© (hash: {desc_hash[:8]}...)")
            return self.cache[desc_hash]
        
        # Llamar a la IA / Voki la AI / Call the AI
        logger.info(f"ü§ñ Procesando con {self.provider}/{self.model}...")
        
        try:
            if self.provider == "openai":
                result = self._call_openai(job_data)
            elif self.provider == "anthropic":
                result = self._call_anthropic(job_data)
            else:
                logger.error(f"‚úó Provider no soportado: {self.provider}")
                return None
            
            # Guardar en cach√© / Konservi en ka≈ùmemoron / Save to cache
            if result and use_cache:
                self.cache[desc_hash] = result
                self._save_cache()
            
            return result
            
        except Exception as e:
            logger.error(f"‚úó Error procesando con IA: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def _call_openai(self, job_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Llama a la API de OpenAI"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._build_system_prompt()},
                    {"role": "user", "content": self._build_user_prompt(job_data)}
                ],
                temperature=0.1,  # Baja temperatura para respuestas consistentes
                response_format={"type": "json_object"}  # Forzar JSON
            )
            
            content = response.choices[0].message.content
            result = json.loads(content)
            
            logger.info("‚úì Respuesta de OpenAI recibida y parseada")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"‚úó Error parseando JSON de OpenAI: {e}")
            logger.error(f"Contenido recibido: {content}")
            return None
        except Exception as e:
            logger.error(f"‚úó Error llamando a OpenAI: {e}")
            return None
    
    def _call_anthropic(self, job_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Llama a la API de Anthropic (Claude)"""
        try:
            message = self.client.messages.create(
                model=self.model,
                max_tokens=1024,
                system=self._build_system_prompt(),
                messages=[
                    {"role": "user", "content": self._build_user_prompt(job_data)}
                ],
                temperature=0.1
            )
            
            content = message.content[0].text
            
            # Claude a veces envuelve en ```json, limpiarlo
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            elif content.startswith("```"):
                content = content.replace("```", "").strip()
            
            result = json.loads(content)
            
            logger.info("‚úì Respuesta de Claude recibida y parseada")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"‚úó Error parseando JSON de Claude: {e}")
            logger.error(f"Contenido recibido: {content}")
            return None
        except Exception as e:
            logger.error(f"‚úó Error llamando a Claude: {e}")
            return None
    
    def enrich_job_data(
        self, 
        job_id: int = None,
        limit: int = 10,
        force_reprocess: bool = False
    ) -> Dict[str, int]:
        """
        Enriquece trabajos en la BD con datos procesados por IA
        Pliriƒâigas laborojn en la datumbazo per AI-traktitaj datumoj
        Enriches jobs in DB with AI-processed data
        
        Args:
            job_id: ID espec√≠fico de trabajo (si None, procesa m√∫ltiples)
            limit: Cantidad m√°xima de trabajos a procesar
            force_reprocess: Si True, reprocesa incluso si ya fue procesado
            
        Returns:
            Diccionario con estad√≠sticas: {processed, failed, skipped}
        """
        stats = {
            'processed': 0,
            'failed': 0,
            'skipped': 0,
            'cached': 0
        }
        
        logger.info("="*80)
        logger.info("üöÄ INICIANDO ENRIQUECIMIENTO CON IA")
        logger.info("="*80)
        
        with get_db() as db:
            # Construir query / Konstrui peton / Build query
            if job_id:
                jobs = db.query(Job).filter(Job.id == job_id).all()
            else:
                # Trabajos no procesados o a reprocesar
                if force_reprocess:
                    jobs = db.query(Job).limit(limit).all()
                else:
                    jobs = db.query(Job).filter(
                        and_(
                            Job.ai_processed == False,
                            Job.description.isnot(None)
                        )
                    ).limit(limit).all()
            
            total_jobs = len(jobs)
            logger.info(f"üìä Trabajos a procesar: {total_jobs}")
            
            if total_jobs == 0:
                logger.info("‚úì No hay trabajos pendientes de procesar")
                return stats
            
            # Procesar cada trabajo / Trakti ƒâiun laboron / Process each job
            for i, job in enumerate(jobs, 1):
                logger.info(f"\nüîÑ Procesando {i}/{total_jobs}: {job.title}")
                
                # Verificar si ya est√° en cach√© por hash
                desc_hash = self._compute_hash(job.description or "")
                cached = desc_hash in self.cache
                
                if cached:
                    logger.info(f"   ‚ö° Usando datos cacheados")
                    stats['cached'] += 1
                
                # Procesar con IA
                ai_result = self.process_description({
                    'title': job.title,
                    'company_name': job.company_name,
                    'location': job.location,
                    'description': job.description
                })
                
                if not ai_result:
                    logger.warning(f"   ‚úó Fallo al procesar")
                    stats['failed'] += 1
                    continue
                
                # Actualizar el trabajo con los datos de IA
                try:
                    # Tech stack (como JSON string)
                    if 'tech_stack' in ai_result:
                        job.stack = json.dumps(ai_result['tech_stack'])
                    
                    # Seniority level
                    if 'seniority_level' in ai_result:
                        job.seniority_level = ai_result['seniority_level']
                    
                    # Remote
                    if 'is_remote' in ai_result:
                        job.is_remote = ai_result['is_remote']
                    
                    # Salary estimate
                    if 'salary_estimate' in ai_result:
                        job.salary_estimate = ai_result['salary_estimate']
                    
                    # Hiring intent
                    if 'hiring_intent' in ai_result:
                        job.hiring_intent = ai_result['hiring_intent']
                    
                    # Red flags (como JSON string)
                    if 'red_flags' in ai_result:
                        job.red_flags = json.dumps(ai_result['red_flags'])
                    
                    # Metadatos de procesamiento
                    job.ai_processed = True
                    job.ai_processed_at = datetime.utcnow()
                    job.description_hash = desc_hash
                    
                    db.commit()
                    
                    logger.info(f"   ‚úì Trabajo actualizado")
                    logger.info(f"      Seniority: {job.seniority_level}")
                    logger.info(f"      Stack: {len(ai_result.get('tech_stack', []))} techs")
                    logger.info(f"      Red Flags: {len(ai_result.get('red_flags', []))}")
                    
                    stats['processed'] += 1
                    
                except Exception as e:
                    db.rollback()
                    logger.error(f"   ‚úó Error actualizando BD: {e}")
                    stats['failed'] += 1
        
        # Resumen final
        logger.info("\n" + "="*80)
        logger.info("üìä RESUMEN DE PROCESAMIENTO")
        logger.info("="*80)
        logger.info(f"‚úì Procesados: {stats['processed']}")
        logger.info(f"‚ö° Desde cach√©: {stats['cached']}")
        logger.info(f"‚úó Fallidos: {stats['failed']}")
        logger.info(f"‚è≠Ô∏è  Saltados: {stats['skipped']}")
        logger.info("="*80)
        
        return stats


def get_ai_processor(provider: str = "openai") -> AIJobProcessor:
    """
    Factory function para obtener un procesador de IA
    Fabrika funkcio por akiri AI-traktilon
    Factory function to get an AI processor
    """
    return AIJobProcessor(provider=provider)


# Ejemplo de uso / Ekzemplo de uzo / Usage example
if __name__ == "__main__":
    # Configurar logging para test
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ü§ñ AI Processor Module - Test Mode")
    print("="*80)
    print("\nPara usar este m√≥dulo:")
    print("1. Configura OPENAI_API_KEY o ANTHROPIC_API_KEY en tu .env")
    print("2. Importa: from src.ai_processor import get_ai_processor")
    print("3. Usa: processor = get_ai_processor()")
    print("4. Ejecuta: processor.enrich_job_data(limit=10)")
    print("\nVer: test_ai_processor.py para ejemplos completos")
