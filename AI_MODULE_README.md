# ü§ñ M√≥dulo de Inteligencia Artificial - Labortrovilo

## üìã Descripci√≥n

El m√≥dulo de IA de Labortrovilo procesa descripciones de trabajos extra√≠das mediante web scraping y las enriquece con informaci√≥n estructurada usando **Large Language Models (LLMs)**.

### üéØ Arquitectura: Senior AI Engineer

**Versi√≥n:** 2.1.0  
**Autor:** Daniel - Senior AI Engineer

---

## üöÄ Caracter√≠sticas Principales

### ‚úÖ Extracci√≥n Estructurada con IA

El m√≥dulo procesa descripciones brutas y extrae:

1. **`tech_stack`** - Lista limpia de tecnolog√≠as
   - Ejemplo: `['Python', 'Django', 'PostgreSQL', 'AWS', 'Docker']`
   - Normalizaci√≥n autom√°tica de nombres

2. **`seniority_level`** - Clasificaci√≥n de nivel
   - Valores: `Intern`, `Junior`, `Mid`, `Senior`, `Lead`, `C-Level`
   - Basado en a√±os de experiencia y palabras clave

3. **`is_remote`** - Trabajo remoto (Boolean)
   - Detecta: "remote", "work from home", "anywhere"
   - Actualiza el campo existente en la BD

4. **`salary_estimate`** - Estimaci√≥n salarial
   - Si est√° expl√≠cito, lo extrae
   - Si no, estima bas√°ndose en: seniority + ubicaci√≥n + stack
   - Formato: `"$80k-$120k USD"` o `"‚Ç¨60k-‚Ç¨90k EUR"`

5. **`hiring_intent`** - Intenci√≥n de contrataci√≥n
   - `"growth"`: Expansi√≥n del equipo, nuevo proyecto
   - `"replacement"`: Reemplazo de alguien que se fue

6. **`red_flags`** - ‚ö†Ô∏è Problemas potenciales (Lista)
   - "Demasiadas tecnolog√≠as no relacionadas"
   - "Horarios poco claros"
   - "Salario muy bajo para el nivel"
   - "Requisitos irreales"
   - "Cultura t√≥xica" (ej: "ninjas", "rockstars")
   - "Descripci√≥n vaga"

---

## üîß Instalaci√≥n

### Paso 1: Instalar dependencias

```bash
pip install openai anthropic
```

O actualiza desde `requirements.txt`:

```bash
pip install -r requirements.txt
```

### Paso 2: Configurar API Keys

Edita tu archivo `.env`:

```env
# OpenAI (recomendado)
OPENAI_API_KEY=sk-proj-your-key-here

# O Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Configuraci√≥n
AI_PROVIDER=openai
AI_MODEL=gpt-4o-mini
AI_CACHE_ENABLED=true
```

**¬øD√≥nde obtener las API keys?**

- **OpenAI:** https://platform.openai.com/api-keys
- **Anthropic:** https://console.anthropic.com/

### Paso 3: Actualizar la base de datos

El m√≥dulo de IA agrega nuevos campos a la tabla `jobs`. Necesitas actualizar tu BD:

```bash
# Opci√≥n 1: Recrear la BD (PERDER√ÅS DATOS)
rm labortrovilo.db
python -c "from src.database import init_db; init_db()"

# Opci√≥n 2: Usar Alembic para migraciones (recomendado para producci√≥n)
alembic revision --autogenerate -m "Add AI fields"
alembic upgrade head
```

---

## üíª Uso

### Opci√≥n 1: Script Interactivo (RECOMENDADO)

```bash
python test_ai_processor.py
```

Men√∫ con opciones:
1. Crear trabajos de ejemplo
2. Test de procesamiento individual
3. Test de procesamiento en lote
4. Test de sistema de cach√©
5. Ver trabajos procesados
6. Salir

### Opci√≥n 2: Uso Program√°tico

```python
from src.ai_processor import get_ai_processor
from src.database import init_db

# Inicializar BD
init_db()

# Crear procesador
processor = get_ai_processor(provider="openai")

# Opci√≥n A: Enriquecer todos los trabajos no procesados
stats = processor.enrich_job_data(limit=10)
print(f"Procesados: {stats['processed']}")

# Opci√≥n B: Procesar un trabajo espec√≠fico
stats = processor.enrich_job_data(job_id=1)

# Opci√≥n C: Forzar reprocesamiento
stats = processor.enrich_job_data(limit=5, force_reprocess=True)
```

### Opci√≥n 3: Procesamiento Individual

```python
from src.ai_processor import get_ai_processor

processor = get_ai_processor()

job_data = {
    'title': 'Senior Backend Engineer',
    'company_name': 'TechCorp',
    'location': 'San Francisco, CA',
    'description': '''
    We're looking for a Senior Backend Engineer with 5+ years experience.
    Requirements: Python, Django, PostgreSQL, AWS, Docker.
    Salary: $120k-$160k. Remote OK.
    '''
}

result = processor.process_description(job_data)

print(result)
# Output:
# {
#   "tech_stack": ["Python", "Django", "PostgreSQL", "AWS", "Docker"],
#   "seniority_level": "Senior",
#   "is_remote": true,
#   "salary_estimate": "$120k-$160k USD",
#   "hiring_intent": "growth",
#   "red_flags": []
# }
```

---

## üéØ Sistema de Cach√©

### ¬øPor qu√© es importante?

Cada llamada a la API de OpenAI/Claude tiene un costo en tokens. El sistema de cach√© **evita procesar descripciones id√©nticas m√∫ltiples veces**.

### ¬øC√≥mo funciona?

1. Calcula un **hash SHA256** de la descripci√≥n
2. Busca el hash en `cache_ai_processing.json`
3. Si existe ‚Üí **usa el resultado cacheado** (gratis!)
4. Si no existe ‚Üí llama a la API y guarda el resultado

### Estad√≠sticas de cach√©

```python
stats = processor.enrich_job_data(limit=100)

print(f"Procesados: {stats['processed']}")
print(f"Desde cach√©: {stats['cached']}")  # ¬°Ahorros!
print(f"Fallidos: {stats['failed']}")
```

### Gesti√≥n del cach√©

```python
# Ver tama√±o del cach√©
import json
with open('cache_ai_processing.json') as f:
    cache = json.load(f)
    print(f"Entradas en cach√©: {len(cache)}")

# Limpiar cach√© (si necesitas reprocesar todo)
import os
os.remove('cache_ai_processing.json')
```

---

## üí∞ Optimizaci√≥n de Costos

### Modelos Recomendados

| Provider | Modelo | Costo (aprox) | Velocidad | Calidad |
|----------|--------|---------------|-----------|---------|
| OpenAI | `gpt-4o-mini` | $0.15/1M tokens | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| OpenAI | `gpt-4o` | $2.50/1M tokens | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Anthropic | `claude-3-haiku` | $0.25/1M tokens | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Anthropic | `claude-3-sonnet` | $3.00/1M tokens | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

**Recomendaci√≥n:** Usa `gpt-4o-mini` para producci√≥n (excelente balance costo/calidad)

### Tips para Ahorrar

1. **Usa el cach√©** - Activa `AI_CACHE_ENABLED=true`
2. **Trunca descripciones largas** - El c√≥digo trunca a 4000 chars autom√°ticamente
3. **Procesa en lotes peque√±os** - Empieza con `limit=10` para testing
4. **Temperature baja** - Usa `temperature=0.1` para respuestas consistentes
5. **Evita reprocesar** - Filtra `WHERE ai_processed = False`

### Estimaci√≥n de Costos

Ejemplo con **gpt-4o-mini** ($0.15/1M tokens):

- **Descripci√≥n promedio:** 500 tokens
- **Respuesta JSON:** 200 tokens
- **Total por trabajo:** ~700 tokens
- **Costo por trabajo:** $0.000105 (‚âà $0.0001)

**1,000 trabajos = ~$0.10 USD** üí∞

---

## üìä Campos en la Base de Datos

Nuevos campos agregados a la tabla `jobs`:

```sql
-- Procesados por IA
seniority_level VARCHAR(50),          -- Intern, Junior, Mid, Senior, Lead, C-Level
salary_estimate VARCHAR(100),         -- Estimaci√≥n si no est√° expl√≠cita
hiring_intent VARCHAR(50),            -- growth o replacement
red_flags TEXT,                       -- JSON array de problemas
ai_processed BOOLEAN DEFAULT FALSE,   -- ¬øYa procesado?
ai_processed_at DATETIME,             -- Timestamp de procesamiento
description_hash VARCHAR(64)          -- SHA256 para cach√©
```

### Consultas SQL √ötiles

```sql
-- Trabajos procesados por IA
SELECT * FROM jobs WHERE ai_processed = TRUE;

-- Trabajos con red flags
SELECT title, company_name, red_flags 
FROM jobs 
WHERE red_flags IS NOT NULL AND red_flags != '[]';

-- Distribuci√≥n por seniority
SELECT seniority_level, COUNT(*) as count 
FROM jobs 
GROUP BY seniority_level;

-- Trabajos por intenci√≥n de contrataci√≥n
SELECT hiring_intent, COUNT(*) as count 
FROM jobs 
GROUP BY hiring_intent;
```

---

## üîç Ejemplo Completo: Flujo End-to-End

```python
"""
Flujo completo: Scraping ‚Üí IA ‚Üí An√°lisis
"""
import asyncio
from src.scraper_engine import LabortroviloScraper
from src.ai_processor import get_ai_processor
from src.database import init_db, get_db
from src.models import Job

async def main():
    # 1. Inicializar BD
    init_db()
    
    # 2. Scrapear trabajos
    scraper = LabortroviloScraper(headless=True)
    await scraper.initialize()
    
    urls = [
        "https://www.workatastartup.com/jobs/70123",
        "https://boards.greenhouse.io/company/jobs/123456",
    ]
    
    results = await scraper.scrape_multiple_jobs(urls)
    await scraper.close()
    
    print(f"‚úì Scrapeados: {sum(1 for r in results if r.success)} trabajos")
    
    # 3. Procesar con IA
    processor = get_ai_processor(provider="openai")
    stats = processor.enrich_job_data(limit=10)
    
    print(f"‚úì Procesados con IA: {stats['processed']} trabajos")
    print(f"‚ö° Desde cach√©: {stats['cached']}")
    
    # 4. An√°lizar resultados
    with get_db() as db:
        # Trabajos Senior con red flags
        senior_with_flags = db.query(Job).filter(
            Job.seniority_level == "Senior",
            Job.red_flags.isnot(None)
        ).all()
        
        print(f"\n‚ö†Ô∏è Trabajos Senior con Red Flags: {len(senior_with_flags)}")
        
        for job in senior_with_flags:
            print(f"\n{job.title} @ {job.company_name}")
            print(f"Flags: {job.red_flags}")

asyncio.run(main())
```

---

## üß™ Testing

### Tests Disponibles

```bash
# Test completo con men√∫ interactivo
python test_ai_processor.py

# O ejecuta tests individuales program√°ticamente
python -c "from test_ai_processor import test_single_job_processing; test_single_job_processing()"
```

### Crear Datos de Prueba

El script de test incluye funci√≥n para crear trabajos de ejemplo:

```python
from test_ai_processor import create_sample_jobs
create_sample_jobs()
```

Crea 3 trabajos:
1. **Senior Backend Engineer** - Caso normal
2. **Junior Frontend Developer** - Nivel junior
3. **Full Stack Ninja Rockstar** - ‚ö†Ô∏è M√∫ltiples red flags

---

## üö® Troubleshooting

### Error: "OPENAI_API_KEY no configurada"

**Soluci√≥n:** Agrega tu API key al archivo `.env`

```env
OPENAI_API_KEY=sk-proj-your-key-here
```

### Error: "ModuleNotFoundError: No module named 'openai'"

**Soluci√≥n:** Instala las dependencias

```bash
pip install openai anthropic
```

### Error: "RateLimitError" (l√≠mite de API)

**Soluci√≥n:** 
- Espera unos segundos y reintenta
- Reduce el `limit` en `enrich_job_data()`
- Usa un modelo m√°s barato como `gpt-4o-mini`

### Error: JSON parsing failed

**Causa:** La IA devolvi√≥ texto mal formateado

**Soluci√≥n:** El c√≥digo ya incluye manejo de errores. Verifica los logs:

```bash
tail -f logs/scraper.log
```

---

## üìà Roadmap Futuro

### Iteraci√≥n 3: Mejoras de IA (Planificado)

- [ ] **Embeddings** para b√∫squeda sem√°ntica de trabajos
- [ ] **Clasificaci√≥n multi-label** de categor√≠as t√©cnicas
- [ ] **An√°lisis de sentimiento** en descripciones
- [ ] **Detecci√≥n de bias** en ofertas de trabajo
- [ ] **Recomendaci√≥n de trabajos** basada en perfil
- [ ] **Generaci√≥n de cover letters** personalizadas
- [ ] **Traducci√≥n autom√°tica** a m√∫ltiples idiomas

### Iteraci√≥n 4: Optimizaciones

- [ ] **Batch processing** con asyncio
- [ ] **Redis** como cach√© distribuido
- [ ] **Queue system** (Celery/RQ) para procesamiento as√≠ncrono
- [ ] **Monitoring** de costos de API
- [ ] **A/B testing** entre modelos (GPT vs Claude)

---

## üìö Referencias

- [Documentaci√≥n OpenAI](https://platform.openai.com/docs/guides/text-generation)
- [Documentaci√≥n Anthropic](https://docs.anthropic.com/claude/docs)
- [Pydantic Settings](https://docs.pydantic.dev/latest/concepts/pydantic_settings/)
- [SQLAlchemy ORM](https://docs.sqlalchemy.org/en/20/orm/)

---

## üôã Soporte

Si encuentras problemas:

1. Revisa los logs: `logs/scraper.log`
2. Verifica tu API key en `.env`
3. Aseg√∫rate de tener cr√©ditos en tu cuenta de OpenAI/Anthropic
4. Consulta esta documentaci√≥n

---

**¬°M√≥dulo de IA listo para usar!** üöÄü§ñ

*Desarrollado por Daniel - Senior AI Engineer*  
*Versi√≥n 2.1.0 - Diciembre 2025*
