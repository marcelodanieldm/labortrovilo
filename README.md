# ğŸ” Labortrovilo

**Una herramienta alternativa para encontrar trabajos de IT fuera de los portales clÃ¡sicos.**  
**Alia ilo por trovi laborojn, krom plej uzataj laborportaloj.**  
**An alternative tool to find IT jobs outside classic job portals.**

---

## ğŸ“– DescripciÃ³n / Priskribo / Description

**Labortrovilo** es una plataforma de scraping inteligente diseÃ±ada con **arquitectura de Senior Data Engineer** que extrae ofertas de trabajo de mÃºltiples fuentes ATS (Applicant Tracking Systems) y las almacena en una base de datos estructurada. Utiliza Playwright para navegaciÃ³n web avanzada, SQLAlchemy para persistencia de datos y Pydantic para validaciÃ³n robusta.

**Labortrovilo** estas inteligenta skrapada platformo dezajnita kun **Seniora Datumingeniisto arkitekturo** kiu ekstraktas laborofertojn de multaj ATS-fontoj (Applicant Tracking Systems) kaj stokas ilin en strukturita datumbazo. Äœi uzas Playwright por altnivela retumado, SQLAlchemy por datuma persisteco kaj Pydantic por fortika validigo.

**Labortrovilo** is an intelligent scraping platform designed with **Senior Data Engineer architecture** that extracts job offers from multiple ATS sources (Applicant Tracking Systems) and stores them in a structured database. It uses Playwright for advanced web navigation, SQLAlchemy for data persistence, and Pydantic for robust validation.

### ğŸ¯ Campos Diferenciadores / Distingaj Kampoj / Differentiating Fields

- **`hiring_urgency_score`** (0-100): Score inteligente que calcula la urgencia de contrataciÃ³n basÃ¡ndose en seÃ±ales del mercado
- **`is_it_niche`**: Detector automÃ¡tico de nichos especializados de IT (blockchain, quantum, AI, etc.)

---

## âœ¨ CaracterÃ­sticas Principales / Äˆefaj Trajtoj / Main Features

### ğŸ¯ TecnologÃ­a / Teknologio / Technology
- âœ… **Python 3.13+** - Lenguaje principal / Äˆefa lingvo / Main language
- âœ… **Playwright for Python** - Web scraping moderno y confiable / Moderna kaj fidinda retskrapado / Modern and reliable web scraping
- âœ… **SQLAlchemy 2.0+** - ORM para gestiÃ³n de base de datos / ORM por datumbaza administrado / ORM for database management
- âœ… **Pydantic 2.0+** - ValidaciÃ³n de datos con tipos / Datumvalidigo kun tipoj / Type-safe data validation
- âœ… **SQLite** - Base de datos integrada / Integrita datumbazo / Embedded database
- âœ… **AsyncIO** - ProgramaciÃ³n asÃ­ncrona nativa / Nesinkrona programado / Native async programming

### ğŸ”§ Funcionalidades / Funkcioj / Functionalities
- ğŸŒ **Scraping asÃ­ncrono** con Playwright para mejor rendimiento
- ğŸ—„ï¸ **Base de datos relacional** con tablas Jobs y Companies optimizadas
- âœ… **ValidaciÃ³n automÃ¡tica** con Pydantic antes de inserciÃ³n
- ğŸš« **PrevenciÃ³n de duplicados** mediante URLs Ãºnicas con Ã­ndices
- ğŸ“Š **Seguimiento de empresas** con mÃ©tricas de crecimiento
- ğŸ’° **ExtracciÃ³n de salarios** con parsing inteligente
- ğŸ·ï¸ **Stack tecnolÃ³gico** identificado y limpio
- ğŸ“ **DocumentaciÃ³n trilingÃ¼e** (EspaÃ±ol/Esperanto/InglÃ©s) en todo el cÃ³digo
- ğŸ›¡ï¸ **Manejo robusto de errores** - el scraper NO se detiene ante fallos
- ğŸ“Š **Sistema de logging** completo con archivos y consola
- ğŸ¯ **DetecciÃ³n inteligente de ATS** (Greenhouse, Lever, Workday, etc.)
- ğŸš€ **Arquitectura modular** lista para escalar
- ğŸ¤– **NEW: MÃ³dulo de IA** - Procesamiento con LLMs (GPT-4, Claude) para anÃ¡lisis inteligente

---

## ğŸ“ Estructura del Proyecto / Projekta Strukturo / Project Structure

```
laboğŸ ARCHIVOS PYTHON (Activos) / PYTHON DOSIEROJ (Aktivaj)
â”‚   â”œâ”€â”€ engine.py              # Motor principal de scraping / Äˆefa skrapada motoro
â”‚   â”œâ”€â”€ models.py              # Modelos de base de datos / Datumbazaj modeloj
â”‚   â”œâ”€â”€ schemas.py             # Esquemas de validaciÃ³n Pydantic / Pydantic validigaj skemoj
â”‚   â”œâ”€â”€ database.py            # ConfiguraciÃ³n de BD / Datumbaza agordado
â”‚   â”œâ”€â”€ config.py              # Ajustes centralizados / Centra agordado
â”‚   â”œâ”€â”€ playwright_config.py   # ConfiguraciÃ³n Playwright Python / Playwright Python agordado
â”‚   â”œâ”€â”€ requirements.txt       # Dependencias Python / Python dependecoj
â”‚   â””â”€â”€ MIGRATION_NOTE.py      # Nota de migraciÃ³n a Python / Noto pri migrado al Python
â”‚
â”œâ”€â”€ ğŸ“ CONFIGURACIÃ“N / AGORDADO / CONFIGURATION
â”‚   â”œâ”€â”€ .env.example          # Variables de entorno ejemplo / Ekzempla medio-variabloj
â”‚   â”œâ”€â”€ .gitignore            # Archivos ignorados / Ignoritaj dosieroj
â”‚   â””â”€â”€ README.md             # DocumentaciÃ³n / Dokumentado
â”‚
â”œâ”€â”€ ğŸ“¦ LEGACY (No se usan) / HEREDAÄ´O (Ne uzataj) / LEGACY (Not used)
â”‚   â”œâ”€â”€ scrap.js              # âš ï¸ Script legacy JavaScript
â”‚   â”œâ”€â”€ scrapATS.js           # âš ï¸ Queries legacy ATS
â”‚   â”œâ”€â”€ playwright.config.js  # âš ï¸ Config legacy JavaScript
â”‚   â””â”€â”€ package.json          # Solo para referencia / Nur por referenco
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ DIRECTORIOS / DOSIERUJOJ / DIRECTORIES
â”‚   â”œâ”€â”€ venv/                 # Entorno virtual Python / Python virtuala medio
â”‚   â”œâ”€â”€ tests/                # Pruebas legacy JS / HeredaÄµaj testoj
â”‚   â””â”€â”€ playwright-report/    # Reportes / Raportoj
â”‚
â””â”€â”€ ğŸ—„ï¸ BASE DE DATOS / DATUMBAZO / DATABASE
    â”œâ”€â”€ playwright-report/    # Reportes de Playwright / Playwright raportoj
â””â”€â”€ labortrovilo.db       # Base de datos SQLite / SQLite datumbazo
```

---

## âš ï¸ NOTA IMPORTANTE / GRAVA NOTO / IMPORTANT NOTE

**Este proyecto usa Playwright con PYTHON exclusivamente.**  
**Äˆi tiu projekto uzas Playwright kun PYTHON ekskluzive.**  
**This project uses Playwright with PYTHON exclusively.**

Los archivos JavaScript (`scrap.js`, `playwright.config.js`) son legacy y no se utilizan. El motor de scraping estÃ¡ implementado completamente en Python.

---

## ğŸš€ InstalaciÃ³n / Instalado / Installation

### Prerrequisitos / AntaÅ­kondiÄ‰oj / Prerequisites

- **Python 3.13+** (requerido / necesa / required)
- **Git**
- ConexiÃ³n a internet / Interreta konekto / Internet connection
- **NO se requiere Node.js** / Node.js ne necesas / Node.js not required

### Paso 1: Clonar el repositorio / PaÅo 1: Kloni la deponejon / Step 1: Clone repository

```bash
git clone https://github.com/tu-usuario/labortrovilo.git
cd labortrovilo
```

### Paso 2: Crear entorno virtual / PaÅo 2: Krei virtualan medion / Step 2: Create virtual environment

```bash
python -m venv venv
```

### Paso 3: Activar entorno virtual / PaÅo 3: Aktivigi virtualan medion / Step 3: Activate virtual environment

**Windows:**
```bash
venv\Scripts\activate
```

**Linux/Mac:**
```bash
source venv/bin/activate
```

### Paso 4: Instalar dependencias / PaÅo 4: Instali dependecojn / Step 4: Install dependencies

```bash
pip install -r requirements.txt
```

### Paso 5: Instalar navegadores Playwright / PaÅo 5: Instali Playwright retumilojn / Step 5: Install Playwright browsers

```bash
playwright install chromium
```

### Paso 6: Configurar variables de entorno / PaÅo 6: Agordi medio-variablojn / Step 6: Configure environment variables

```bash
### Paso 7: Ejecutar test bÃ¡sico / PaÅo 7: Plenumi bazan teston / Step 7: Run basic test

```bash
python test_scraper.py
```

---

## ğŸ’» Uso / Uzo / Usage

### â­ OpciÃ³n 1: Script de Test Interactivo (RECOMENDADO)

```bash
python test_scraper.py
```

MenÃº interactivo con opciones:
1. Test completo (BD + Scraping)
2. Test solo de Base de Datos
3. Salir

### OpciÃ³n 2: Usar el Motor de Scraping Directamente

```python
import asyncio
from src.scraper_engine import LabortroviloScraper
from src.database import init_db

async def main():
    # Inicializar base de datos
    init_db()
    
    # Crear scraper
    scraper = LabortroviloScraper(headless=True)
    
    try:
        await scraper.initialize()
        
        # Scrapear una URL
        result = await scraper.scrape_job("https://example.com/job")
        
        print(f"Ã‰xito: {result.success}")
        if result.job_data:
            print(f"TÃ­tulo: {result.job_data.title}")
            print(f"Urgency Score: {result.job_data.hiring_urgency_score}")
   external_id` | String(255) | ID externo del ATS / Ekstera ATS-ID / External ATS ID |
| `title` | String(255) | TÃ­tulo del trabajo / Labortitolo / Job title |
| `company_id` | Integer (FK) | ID de empresa / Kompania ID / Company ID |
| `company_name` | String(255) | Nombre empresa (denorm.) / Kompania nomo (denorm.) / Company name (denorm.) |
| `description` | Text | DescripciÃ³n procesada / Traktita priskribo / Processed description |
| `raw_description` | Text | DescripciÃ³n original / Originala priskribo / Original description |
| `stack` | Text | Stack tecnolÃ³gico / Teknologia stako / Tech stack |
| `required_skills` | Text | Habilidades requeridas / Postulataj kapabloj / Required skills |
| `nice_to_have_skills` | Text | Habilidades deseables / Dezireblaj kapabloj / Nice to have skills |
| `salary_range` | String(100) | Rango salarial string / Salajra intervalo / Salary range string |
| `salary_min` | Float | Salario mÃ­nimo / Minimuma salajro / Minimum salary |
| `salary_max` | Float | Salario mÃ¡ximo / Maksimuma salajro / Maximum salary |
| `salary_currency` | String(10) | Moneda (USD, EUR, etc.) / Valuto / Currency |
| `location` | String(200) | UbicaciÃ³n / Loko / Location |
| `is_remote` | Boolean | Â¿Es remoto? / Äˆu malproksima? / Is remote? |
| `remote_policy` | String(50) | PolÃ­tica remota / Malproksima politiko / Remote policy |
| `country` | String(100) | PaÃ­s / Land / Country |
| `city` | String(100) | Ciudad / Urbo / City |
| `source_url` | String(500) | URL fuente (Ãºnica) / Fonta URL (unika) / Source URL (unique) |
| `source_platform` | String(100) | ATS platform / ATS platformo / ATS platform |
| **`hiring_urgency_score`** | **Float (0-100)** | **ğŸ¯ Score de urgencia / UrÄeca poentaro / Urgency score** |
| **`is_it_niche`** | **Boolean** | **ğŸ¯ Â¿Nicho IT? / Äˆu IT-niÄ‰o? / Is IT niche?** |
| `posted_date` | DateTime | Fecha publicaciÃ³n / Publikigdata / Posted date |
| `date_scraped` | DateTime | Fecha extracciÃ³n / Ekstraktdata / Scraped date |
| `last_verified` | DateTime | Ãšltima verificaciÃ³n / Lasta kontrolo / Last verified |
| `is_active` | Boolean | Â¿Activa? / Äˆu aktiva? / Is active? |
| `created_at` | DateTime | Fecha creaciÃ³n / Kredata / Created date |
| `updated_at` | DateTime | Fecha actualizaciÃ³n / Äœisdata / Updated date |
| `scraping_errors` | Integer | Contador de errores / Erarnombro / Error count

### EjecuciÃ³n bÃ¡sica / Baza plenumado / Basic execution

```bash
python engine.py
```

### Personalizar URL objetivo / Personecigi celan URL / Customize target URL

Edita `engine.py` y modifica la URL en la funciÃ³n `main()`:

```python
# REEMPLAZAR CON URL REAL DE OFERTA DE TRABAJO
test_url = "https://boards.greenhouse.io/company/job/123456"
```

### Ejecutar con entorno virtual / Plenumi kun virtuala medio / Run with virtual environment

```bash
venv\Scripts\python.exe engine.py
```

---

## ğŸ—„ï¸ Esquema de Base de Datos / Datumbaza Skemo / Database Schema

### Tabla Companies / Tabelo Companies

| Campo / Campo / Field | Tipo / Tipo / Type | DescripciÃ³n / Priskribo / Description |
|----------------------|-------------------|----------------------------------------|
| `id` | Integer (PK) | Identificador Ãºnico / Unika identigilo / Unique identifier |
| `name` | String(255) | Nombre de empresa (Ãºnico) / Kompania nomo (unika) / Company name (unique) |
| `growth_score` | Float | PuntuaciÃ³n de crecimiento / Kreska poentaro / Growth score |
| `industry` | String(100) | Industria / Industrio / Industry |
| `created_at` | DateTime | Fecha creaciÃ³n / Kredata / Created date |
| `updated_at` | DateTime | Fecha actualizaciÃ³n / Äœisdata / Updated date |

### Tabla Jobs / Tabelo Jobs

| Campo / Campo / Field | Tipo / Tipo / Type | DescripciÃ³n / Priskribo / Description |
|----------------------|-------------------|----------------------------------------|
| `id` | Integer (PK) | Identificador Ãºnico / Unika identigilo / Unique identifier |
| `title` | String(255) | TÃ­tulo del trabajo / Labortitolo / Job title |
| `company_id` | Integer (FK) | ID de empresa / Kompania ID / Company ID |
| `company_name` | String(255) | Nombre empresa (denorm.) / Kompania nomo (denorm.) / Company name (denorm.) |
| `raw_description` | Text | DescripciÃ³n original / Originala priskribo / Original description |
| `cleaned_stack` | Text | Stack tecnolÃ³gico limpio / Purigita teknologia stako / Cleaned tech stack |
| `salary_min` | Float | Salario mÃ­nimo / Minimuma salajro / Minimum salary |
| `salary_max` | Float | Salario mÃ¡ximo / Maksimuma salajro / Maximum salary |
| `source_url` | String(500) | URL fuente (Ãºnica) / Fonta URL (unika) / Source URL (unique) |
| `posted_date` | DateTime | Fecha publicaciÃ³n / Publikigdata / Posted date |
| `scraped_at` | DateTime | Fecha extracciÃ³n / Ekstraktdata / Scraped date |
| `updated_at` | DateTime | Fecha actualizaciÃ³n / Äœisdata / Updated date |

---

## ğŸ¯ ATS Soportados / Subtenataj ATS / Supported ATS

El sistema estÃ¡ diseÃ±ado para trabajar con los siguientes sistemas ATS:

- ğŸŸ¢ **Greenhouse** - `boards.greenhouse.io`
- ğŸŸ¢ **Lever** - `jobs.lever.co`
- ğŸŸ¢ **Workday** - `myworkdayjobs.com`
- ğŸŸ¢ **SmartRecruiters** - `smartrecruiters.com`
- ğŸŸ¢ **Workable** - `workable.com`
- ğŸŸ¢ **BambooHR** - `bamboohr.com`
- ğŸŸ¢ **Jobvite** - `jobvite.com`
- ğŸŸ¢ **iCIMS** - `icims.com`
- ğŸŸ¢ **Google Careers** - `careers.google.com`
config.py`:

```python
class Settings(BaseSettings):
    DEBUG_SQL: bool = True  # â† Cambiar a True
```

### Ver base de datos / Vidi datumbazon / View database

```bash
# Instalar SQLite viewer / Instali SQLite vidigilo
pip install sqlite-web

# Ejecutar / Plenumi / Run
sqlite_web labortrovilo.db
```

### Ver estadÃ­sticas de BD / Vidi datumbazajn statistikojn / View DB stats

```python
from src.database import db_manager

stats = db_manager.get_stats()
print(stats)
# Output: {'total_jobs': 10, 'totaltrilingÃ¼es (EspaÃ±ol/Esperanto/InglÃ©s):

```python
# Inicializar base de datos / Ekigi datumbazon / Initialize database
def init_db():
    """
    Inicializa la base de datos creando todas las tablas
    Ekigas la datumbazon kreante Ä‰iujn tabelojn
    Initializes the database creating all tables
    """
    # Crear todas las tablas / Krei Ä‰iujn tabelojn / Create all tables
    Base.metadata.create_all(bind=engine)
```

### ğŸ“š DocumentaciÃ³n Adicional

- **[QUICKSTART.md](QUICKSTART.md)** - GuÃ­a de inicio rÃ¡pido con ejemplos
- **[src/models.py](src/models.py)** - Esquema completo de base de datos
- **[src/schemas.py](src/schemas.py)** - Todos los esquemas de validaciÃ³n
- **[src/scraper_engine.py](src/scraper_engine.py)** - Motor de scraping documentado
- **[config.py](config.py)** - Todas las opciones configurables-Content -Path "logs\scraper.log" -Tail 20 -Wait

# Linux/Mac
tail -f logs/scraper.log
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
```

---

## ğŸ”§ PersonalizaciÃ³n / Personecigo / Customization

### Modificar selectores CSS / Modifi CSS-elektilojn / Modify CSS selectors

Edita el mÃ©todo `extract_job_data()` en `engine.py` para adaptar los selectores a tu sitio objetivo:

```python
# Extraer tÃ­tulo / Ekstraki titolon
title = await self.page.locator('h1.job-title').first.text_content()

# Extraer empresa / Ekstraki kompanion
company_name = await self.page.locator('.company-name').first.text_content()
```

### Agregar campos personalizados / Aldoni proprajn kampojn / Add custom fields

1. ğŸ¯ Campos Diferenciadores Implementados

### ğŸš€ hiring_urgency_score (0-100)

Score inteligente que calcula la urgencia de contrataciÃ³n basÃ¡ndose en:

- âœ… **Palabras clave de urgencia**: "urgent", "immediate", "ASAP", "urgente", "inmediato"
- âœ… **Fecha de publicaciÃ³n reciente**: +20 pts si < 3 dÃ­as, +10 pts si < 7 dÃ­as
- âœ… **Indicadores en el tÃ­tulo**: Senior, Lead positions (+5 pts)
- âœ… **Score base**: 50 puntos

**Ejemplo de uso:**
```python
# Jobs con urgency_score > 70 son altamente urgentes
high_urgency_jobs = db.query(Job).filter(Job.hiring_urgency_score > 70).all()
```

### ğŸ¯ is_it_niche (Boolean)

Detecta automÃ¡ticamente nichos especializados de IT:

- âœ… **Blockchain & Web3**: blockchain, web3, crypto, smart contracts
- âœ… **Quantum Computing**: quantum computing, quantum algorithms
- âœ… **AI/ML Avanzado**: deep learning, computer vision, NLP, AI engineer
- âœ… **Bioinformatics**: bioinformatics, computational biology
- âœ… **Embedded Systems**: embedded systems, IoT, edge computing
- âœ… **Graphics Programming**: game engine, shader programming, graphics

**Ejemplo de uso:**
```python
# Filtrar trabajos de nicho especializado
niche_jobs = db.query(Job).filter(Job.is_it_niche == True).all()
```

---

## ğŸ›¡ï¸ Seguridad y Manejo de Errores

### âœ… CaracterÃ­sticas de Seguridad Implementadas

- **Try/Except en todos los mÃ©todos crÃ­ticos**: El scraper nunca se detiene por un error
- **Logging completo**: Todos los errores se registran con traceback en `logs/scraper.log`
- **ValidaciÃ³n Pydantic**: Datos validados antes de insertar en BD
- **PrevenciÃ³n de duplicados**: URLs Ãºnicas con Ã­ndices en BD
- **Health checks**: VerificaciÃ³n de conexiÃ³n a BD antes de operar
- **Rate limiting**: Delays configurables entre requests

### ğŸ“Š Sistema de Logging

```
logs/scraper.log
â”œâ”€â”€ INFO    : Operaciones normales y exitosas
â”œâ”€â”€ WARNING : Situaciones que requieren atenciÃ³n
â”œâ”€â”€ ERROR   : Errores capturados y manejados
â””â”€â”€ CRITICAL: Errores graves del sistema
```

**Ejemplo de log:**
```
2025-12-18 10:30:15 - INFO - ğŸŒ Navegando a: https://example.com/job
2025-12-18 10:30:17 - INFO - âœ“ NavegaciÃ³n exitosa: 200
2025-12-18 10:30:18 - INFO - ğŸ“Š Extrayendo datos de la pÃ¡gina...
2025-12-18 10:30:19 - INFO - âœ“ Datos extraÃ­dos: Senior Python Developer
2025-12-18 10:30:19 - INFO -    ğŸ“ˆ Urgency Score: 75.5
2025-12-18 10:30:19 - INFO -    ğŸ¯ IT Niche: False
2025-12-18 10:30:20 - INFO - âœ… Trabajo guardado en BD: Senior Python Developer (ID: 1)
```

---

## ğŸš§ Roadmap / Planita Evoluado / Planned Development

### âœ… IteraciÃ³n 1: Base de Datos y Motor (COMPLETADO)
- [x] Arquitectura Senior Data Engineer
- [x] Modelos SQLAlchemy con campos diferenciadores
- [x] ValidaciÃ³n Pydantic robusta
- [x] Motor de scraping con Playwright
- [x] Sistema de logging y error handling
- [x] Tests bÃ¡sicos implementados

### âœ… IteraciÃ³n 2: MÃ³dulo de Inteligencia Artificial (COMPLETADO) ğŸ¤–
- [x] IntegraciÃ³n con OpenAI GPT-4 y Anthropic Claude
- [x] Procesamiento estructurado de descripciones con LLMs
- [x] ExtracciÃ³n automÃ¡tica de tech stack normalizado
- [x] ClasificaciÃ³n de seniority level (Intern â†’ C-Level)
- [x] AnÃ¡lisis de red flags en ofertas de trabajo
- [x] EstimaciÃ³n salarial inteligente basada en contexto
- [x] DetecciÃ³n de hiring intent (growth vs replacement)
- [x] Sistema de cachÃ© para optimizaciÃ³n de costos
- [x] DocumentaciÃ³n completa del mÃ³dulo de IA
- [x] Suite de tests para el mÃ³dulo de IA

ğŸ“š **Ver:** [AI_MODULE_README.md](AI_MODULE_README.md) para documentaciÃ³n completa

### IteraciÃ³n 3: AnÃ¡lisis Avanzado y ML
- [ ] Embeddings para bÃºsqueda semÃ¡ntica
- [ ] ClasificaciÃ³n multi-label de categorÃ­as
- [ ] AnÃ¡lisis de tendencias salariales por stack
- [ ] DetecciÃ³n de bias en ofertas de trabajo
- [ ] Sistema de recomendaciÃ³n de trabajos

### IteraciÃ³n 3: Interfaz Web
- [ ] Frontend con React/Vue
- [ ] API REST con FastAPI
- [ ] Sistema de bÃºsqueda y filtros avanzados
- [ ] Dashboards analÃ­ticos con visualizaciones
- [ ] ExportaciÃ³n a CSV/Excel

### IteraciÃ³n 4: AutomatizaciÃ³n
- [ ] Scraping programado (cron jobs)
- [ ] Notificaciones por email
- [ ] IntegraciÃ³n con Telegram/Discord
- [ ] Sistema de alertas personalizadas por urgency_score
- [ ] VerificaciÃ³n automÃ¡tica de vigencia de ofert
    H -->|No| J[Guardar en BD]
    H -->|SÃ­| K[Omitir - ya existe]
    J --> L[Cerrar navegador]
    K --> L
    I --> L
```

---

## ğŸ› ï¸ Desarrollo / Evoluigo / Development

### Ejecutar en modo debug / Plenumi en sencimiga reÄimo / Run in debug mode

Activa logs SQL editando `database.py`:

```python
engine = create_engine(
    settings.DATABASE_URL,
    echo=True,  # â† Cambiar a True / ÅœanÄi al True / Change to True
    ...
)
```

### Ver base de datos / Vidi datumbazon / View database

```bash
# Instalar SQLite viewer / Instali SQLite vidigilo
pip install sqlite-web

# Ejecutar / Plenumi / Run
sqlite_web labortrovilo.db
```

---

## ğŸ“ DocumentaciÃ³n del CÃ³digo / Koda Dokumentado / Code Documentation

Todo el cÃ³digo incluye comentarios bilingÃ¼es (EspaÃ±ol/Esperanto):

```python
# Inicializar base de datos / Ekigi datumbazon
def init_db():
    # Crear todas las tablas / Krei Ä‰iujn tabelojn
    Base.metadata.create_all(bind=engine)
```

---

## ğŸ› SoluciÃ³n de Problemas / Problemsolvado / Troubleshooting

### Error: ModuleNotFoundError: No module named 'playwright'

```bash
pip install playwright
playwright install chromium
```

### Error: SQLAlchemy incompatibility with Python 3.13

```bash
pip install --upgrade "SQLAlchemy>=2.0.35"
```

### Error: Base de datos bloqueada / Database is locked

La base de datos SQLite no soporta alta concurrencia. Considera migrar a PostgreSQL para producciÃ³n.

---

## ğŸš§ Roadmap / Planita Evoluado / Planned Development

### IteraciÃ³n 2: Inteligencia de Datos
- [ ] Procesamiento de lenguaje natural para descripciÃ³n
- [ ] ExtracciÃ³n automÃ¡tica de stack tecnolÃ³gico
- [ ] ClasificaciÃ³n de trabajos por nivel de experiencia
- [ ] AnÃ¡lisis de salarios y tendencias

### IteraciÃ³n 3: Interfaz Web
- [ ] Frontend con React/Vue
- [ ] API REST con FastAPI
- [ ] Sistema de bÃºsqueda y filtros
- [ ] Dashboards analÃ­ticos

### IteraciÃ³n 4: AutomatizaciÃ³n
- [ ] Scraping programado (cron jobs)
- [ ] Notificaciones por email
- [ ] IntegraciÃ³n con Telegram/Discord
- [ ] Sistema de alertas personalizadas

---

## ğŸ¤ ContribuciÃ³n / Kontribui / Contributing

Las contribuciones son bienvenidas / Kontribuoj estas bonvenaj / Contributions are welcome!

1. Fork el proyecto / Forku la projekton / Fork the project
2. Crea tu rama (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“„ Licencia / Permesilo / License

Este proyecto estÃ¡ bajo la licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¤ Autor / AÅ­toro / Author

**Daniel** - [GitHub Profile](https://github.com/tu-usuario)

---

## ğŸ™ Agradecimientos / Dankespreskoj / Acknowledgments

- **Playwright Team** - Por la excelente herramienta de scraping
- **SQLAlchemy** - Por el ORM robusto
- **Pydantic** - Por la validaciÃ³n de datos
- **Comunidad Esperanto** - Por inspirar la documentaciÃ³n bilingÃ¼e

---

## ğŸ“ Contacto / Kontakto / Contact

- ğŸ“§ Email: tu-email@ejemplo.com
- ğŸ’¼ LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)
- ğŸ¦ Twitter: [@tu_usuario](https://twitter.com/tu_usuario)

---

<div align="center">

**Hecho con â¤ï¸ por la comunidad de desarrolladores**  
**Farita kun â¤ï¸ de la komunumo de programistoj**  
**Made with â¤ï¸ by the developer community**

</div>


